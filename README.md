# llm-from-scratch

### Processes
# ðŸ§© LLM Development Processes

- [x] **1. Data Collection** â€” Thu tháº­p hÃ ng TB text data cháº¥t lÆ°á»£ng cao  
- [x] **2. Preprocessing** â€” Cleaning, deduplication, tokenization  
- [x] **3. Architecture** â€” Design Transformer-based model  
- [x] **4. Pre-training** â€” Causal language modeling in massive dataset  
- [x] **5. Fine-tuning** â€” Instruction tuning vÃ  RLHF  
- [x] **6. Evaluation** â€” Benchmark testing vÃ  human evaluation  
- [x] **7. Optimization** â€” Quantization, pruning, distillation  
- [x] **8. Deployment** â€” API serving vÃ  monitoring


### Papers

- **"Attention Is All You Need"** (Vaswani et al., 2017) - Original Transformer
- **"Language Models are Few-Shot Learners"** (Brown et al., 2020) - GPT-3
- **"Training language models to follow instructions with human feedback"** (Ouyang et al., 2022) - InstructGPT
